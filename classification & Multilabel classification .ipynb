{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marakhi\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "#from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_signs.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_signs.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
    "\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n",
    "\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "\n",
    "\n",
    "def forward_propagation_for_predict(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3'] \n",
    "                                                           # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
    "    \n",
    "    return Z3\n",
    "\n",
    "def predict(X, parameters):\n",
    "    \n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "    \n",
    "    params = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3}\n",
    "    \n",
    "    x = tf.placeholder(\"float\", [12288, 1])\n",
    "    \n",
    "    z3 = forward_propagation_for_predict(x, params)\n",
    "    p = tf.argmax(z3)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    prediction = sess.run(p, feed_dict = {x: X})\n",
    "        \n",
    "    return prediction\n",
    "\n",
    "#def predict(X, parameters):\n",
    "#    \n",
    "#    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "#    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "#    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "#    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "##    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "##    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "#    \n",
    "##    params = {\"W1\": W1,\n",
    "##              \"b1\": b1,\n",
    "##              \"W2\": W2,\n",
    "##              \"b2\": b2,\n",
    "##              \"W3\": W3,\n",
    "##              \"b3\": b3}\n",
    "#\n",
    "#    params = {\"W1\": W1,\n",
    "#              \"b1\": b1,\n",
    "#              \"W2\": W2,\n",
    "#              \"b2\": b2}    \n",
    "#    \n",
    "#    x = tf.placeholder(\"float\", [12288, 1])\n",
    "#    \n",
    "#    z3 = forward_propagation(x, params)\n",
    "#    p = tf.argmax(z3)\n",
    "#    \n",
    "#    with tf.Session() as sess:\n",
    "#        prediction = sess.run(p, feed_dict = {x: X})\n",
    "#        \n",
    "#    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(6)\n",
    "b = tf.constant(2, tf.int32)\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(a*b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_29:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    }
   ],
   "source": [
    "x=tf.placeholder(tf.float32)\n",
    "c = (x*2)\n",
    "sess = tf.Session()\n",
    "print(sess.run(c,feed_dict = {x: 4}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.62434536]\n",
      " [-0.61175641]\n",
      " [-0.52817175]]\n",
      "[[-1.07296862  0.86540763 -2.3015387 ]\n",
      " [ 1.74481176 -0.7612069   0.3190391 ]\n",
      " [-0.24937038  1.46210794 -2.06014071]\n",
      " [-0.3224172  -0.38405435  1.13376944]]\n",
      "[[-1.09989127]\n",
      " [-0.17242821]\n",
      " [-0.87785842]\n",
      " [ 0.04221375]]\n",
      "[[-2.15657382]\n",
      " [ 2.95891446]\n",
      " [-1.08926781]\n",
      " [-0.84538042]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "X = np.random.randn(3, 1)\n",
    "W = np.random.randn(4, 3)\n",
    "b = np.random.randn(4, 1)\n",
    "sess = tf.Session()\n",
    "print(sess.run(tf.convert_to_tensor(X)))\n",
    "print(sess.run(tf.convert_to_tensor(W)))\n",
    "print(sess.run(tf.convert_to_tensor(b)))\n",
    "print(sess.run(tf.matmul(W,X)+b))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.62434536]\n",
      " [-0.61175641]\n",
      " [-0.52817175]]\n",
      "[[-1.07296862  0.86540763 -2.3015387 ]\n",
      " [ 1.74481176 -0.7612069   0.3190391 ]\n",
      " [-0.24937038  1.46210794 -2.06014071]\n",
      " [-0.3224172  -0.38405435  1.13376944]]\n",
      "[[-1.09989127]\n",
      " [-0.17242821]\n",
      " [-0.87785842]\n",
      " [ 0.04221375]]\n",
      "[[-2.15657382]\n",
      " [ 2.95891446]\n",
      " [-1.08926781]\n",
      " [-0.84538042]]\n",
      "[[0.22156425]\n",
      " [0.97934476]\n",
      " [0.45282379]\n",
      " [0.5136515 ]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "X = np.random.randn(3, 1)\n",
    "W = np.random.randn(4, 3)\n",
    "b = np.random.randn(4, 1)\n",
    "sess = tf.Session()\n",
    "print(sess.run(tf.convert_to_tensor(X)))\n",
    "print(sess.run(tf.convert_to_tensor(W)))\n",
    "print(sess.run(tf.convert_to_tensor(b)))\n",
    "print(sess.run(tf.matmul(W,X)+b))\n",
    "print(sess.run(tf.sigmoid((tf.matmul(W,X)+b)+0.9)))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31326172\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(tf.nn.sigmoid_cross_entropy_with_logits(logits=1.0, labels=1.0)))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 0, 3, 4, 2, 4, 2, 1])\n",
    "b = np.zeros((5,8))\n",
    "print(b)\n",
    "b[a,np.arange(8)] = 1\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 0, 3, 1, 2])\n",
    "b = np.zeros((4, 5))\n",
    "b[a, np.arange(5)] = 1\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise\\\\Data\\\\image5.JPG')\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "A = 1193\n",
    "for i in range(0,2113,350):\n",
    "    for j in range(0,2961,350):\n",
    "        if i >= 1751 or j >= 2451:\n",
    "            break        \n",
    "        crop_img = img[j:j+350, i:i+350]\n",
    "        resize_img = cv2.resize(crop_img, (35,35), interpolation = cv2.INTER_AREA)\n",
    "        file_name = 'C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise\\\\Data\\\\'+str(A)+'.jpg'\n",
    "        cv2.imwrite(file_name, resize_img)\n",
    "        A = A+1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[141 194 227]\n",
      "  [140 192 228]\n",
      "  [144 196 233]\n",
      "  ...\n",
      "  [178 221 254]\n",
      "  [178 221 254]\n",
      "  [177 220 253]]\n",
      "\n",
      " [[106 165 197]\n",
      "  [109 167 202]\n",
      "  [117 175 210]\n",
      "  ...\n",
      "  [ 91 151 181]\n",
      "  [ 91 151 181]\n",
      "  [ 91 151 181]]\n",
      "\n",
      " [[105 173 202]\n",
      "  [103 170 201]\n",
      "  [111 178 211]\n",
      "  ...\n",
      "  [ 94 168 196]\n",
      "  [ 94 168 196]\n",
      "  [ 94 168 196]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[119 187 216]\n",
      "  [108 176 205]\n",
      "  [119 187 216]\n",
      "  ...\n",
      "  [103 178 204]\n",
      "  [103 178 204]\n",
      "  [103 178 204]]\n",
      "\n",
      " [[124 192 221]\n",
      "  [111 179 208]\n",
      "  [118 186 215]\n",
      "  ...\n",
      "  [103 178 204]\n",
      "  [103 178 204]\n",
      "  [104 179 205]]\n",
      "\n",
      " [[117 185 214]\n",
      "  [106 174 203]\n",
      "  [116 184 213]\n",
      "  ...\n",
      "  [102 177 203]\n",
      "  [103 178 204]\n",
      "  [103 178 204]]]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for filename in glob.glob('C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise\\\\Data\\\\train\\\\p\\\\*.JPG'): \n",
    "    im=cv2.imread(filename)\n",
    "    if i == 0:\n",
    "        x_train=np.expand_dims(im, axis=0)\n",
    "        #plt.imshow(im)\n",
    "        im = np.fliplr(im)\n",
    "        x_train = np.concatenate((x_train, np.expand_dims(im, axis=0)), axis=0)\n",
    "        i=i+1\n",
    "    else:\n",
    "        x_train = np.concatenate((x_train, np.expand_dims(im, axis=0)), axis=0)\n",
    "        im = np.fliplr(im)\n",
    "        x_train = np.concatenate((x_train, np.expand_dims(im, axis=0)), axis=0)\n",
    "        \n",
    "for filename in glob.glob('C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise\\\\Data\\\\train\\\\b\\\\*.JPG'): \n",
    "    im=cv2.imread(filename)\n",
    "    x_train = np.concatenate((x_train, np.expand_dims(im, axis=0)), axis=0)\n",
    "    im = np.fliplr(im)\n",
    "    x_train = np.concatenate((x_train, np.expand_dims(im, axis=0)), axis=0)\n",
    "\n",
    "i = 0\n",
    "for filename in glob.glob('C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise\\\\Data\\\\test\\\\p\\\\*.JPG'): \n",
    "    im=cv2.imread(filename)\n",
    "    if i == 0:\n",
    "        x_test=np.expand_dims(im, axis=0)\n",
    "        i=i+1\n",
    "    else:\n",
    "        x_test = np.concatenate((x_test, np.expand_dims(im, axis=0)), axis=0)\n",
    "        \n",
    "for filename in glob.glob('C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise\\\\Data\\\\test\\\\b\\\\*.JPG'): \n",
    "    im=cv2.imread(filename)\n",
    "    x_test = np.concatenate((x_test, np.expand_dims(im, axis=0)), axis=0)\n",
    "        \n",
    "print(x_test[0,:,:,:])\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "#plt.imshow(x_test[0])\n",
    "# cv2.imshow('img',x_test[47]/255)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=35x35 at 0x16C5CBE4550>\n"
     ]
    }
   ],
   "source": [
    "print(image_list[0])\n",
    "#print (\"X_train shape: \" + str(image_list.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list[200].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(756, 35, 35, 3)\n",
      "(96, 35, 35, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(756, 1)\n",
      "(96, 1)\n"
     ]
    }
   ],
   "source": [
    "# y_train1 = np.zeros(186*2, dtype=int)\n",
    "# y_train1 = np.concatenate((y_train1, np.ones(192*2, dtype=int)), axis=None)\n",
    "# print(y_train1.shape)\n",
    "\n",
    "# y_train = np.zeros((378*2, 2))\n",
    "# y_train[np.arange(378*2), y_train1] = 1\n",
    "# print(y_train.shape)\n",
    "\n",
    "# y_test1 = np.ones(48, dtype=int)\n",
    "# y_test1 = np.concatenate((y_test1, np.zeros(48, dtype=int)), axis=None)\n",
    "# print(y_test1.shape)\n",
    "\n",
    "# y_test = np.zeros((96,2))\n",
    "# y_test[np.arange(96),y_test1] = 1\n",
    "# print(y_test.shape)\n",
    "\n",
    "y_train = np.zeros(186*2, dtype=int)\n",
    "y_train = np.concatenate((y_train, np.ones(192*2, dtype=int)), axis=None)\n",
    "y_train = y_train.reshape((756, 1))\n",
    "print(y_train.shape)\n",
    "\n",
    "y_test = np.zeros(48, dtype=int)\n",
    "y_test = np.concatenate((y_test, np.ones(48, dtype=int)), axis=None)\n",
    "y_test = y_test.reshape((96, 1))\n",
    "print(y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[500])\n",
    "print(y_train[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.876058\n",
      "Cost after epoch 5: 0.846745\n",
      "Cost after epoch 10: 0.965677\n",
      "Cost after epoch 15: 1.019833\n",
      "Cost after epoch 20: 1.150319\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.9973545\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    X = tf.placeholder(tf.float32, [None, n_H0, n_W0, n_C0])\n",
    "    Y = tf.placeholder(tf.float32, [None, n_y])    \n",
    "    return X, Y\n",
    "\n",
    "def initialize_parameters():\n",
    "    tf.set_random_seed(1)                               \n",
    "    W1 = tf.get_variable(\"W1\", [5, 5, 3, 30], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W2 = tf.get_variable(\"W2\", [5, 5, 30, 60], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2}    \n",
    "    return parameters\n",
    "\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    Z1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding='SAME')\n",
    "    Z2 = tf.nn.conv2d(P1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding='SAME')\n",
    "    P = tf.contrib.layers.flatten(P1)\n",
    "    Z3 = tf.contrib.layers.fully_connected(P, 2, activation_fn=None)\n",
    "    return Z3\n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3, labels=Y)) \n",
    "    return cost\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate=0.001,\n",
    "          num_epochs=25, minibatch_size=128, print_cost=True):\n",
    "    \n",
    "    ops.reset_default_graph()                          \n",
    "    tf.set_random_seed(1)                              \n",
    "    seed = 3                                           \n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        \n",
    "    \n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "\n",
    "    cost = compute_cost(Z3, Y)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size)  \n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y})\n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "                \n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        predict_op = tf.argmax(Z3, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(accuracy)\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "                \n",
    "        return train_accuracy, test_accuracy, parameters\n",
    "    \n",
    "_, _, parameters = model(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras \n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils import to_categorical\n",
    "#import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "#from kt_utils import *\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HappyModel(input_shape):\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    X = Conv2D(32, (3, 3), strides = (1, 1), name = 'conv0')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(64, (3, 3), strides = (1, 1), name = 'conv1')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "    X = Dropout(0.25)(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(5, activation='sigmoid', name='fc')(X)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X, name='HappyModel')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "756/756 [==============================] - 29s 38ms/step - loss: 1.0134 - acc: 0.7085\n",
      "Epoch 2/10\n",
      "756/756 [==============================] - 27s 36ms/step - loss: 0.2988 - acc: 0.8606\n",
      "Epoch 3/10\n",
      "756/756 [==============================] - 27s 36ms/step - loss: 0.1595 - acc: 0.9262\n",
      "Epoch 4/10\n",
      "756/756 [==============================] - 27s 35ms/step - loss: 0.0984 - acc: 0.9601\n",
      "Epoch 5/10\n",
      "756/756 [==============================] - 27s 35ms/step - loss: 0.0646 - acc: 0.9799\n",
      "Epoch 6/10\n",
      "756/756 [==============================] - 27s 36ms/step - loss: 0.0532 - acc: 0.9823\n",
      "Epoch 7/10\n",
      "756/756 [==============================] - 28s 37ms/step - loss: 0.0330 - acc: 0.9862\n",
      "Epoch 8/10\n",
      "756/756 [==============================] - 27s 35ms/step - loss: 0.0434 - acc: 0.9881\n",
      "Epoch 9/10\n",
      "756/756 [==============================] - 27s 36ms/step - loss: 0.0409 - acc: 0.9865\n",
      "Epoch 10/10\n",
      "756/756 [==============================] - 27s 36ms/step - loss: 0.0291 - acc: 0.9921\n",
      "Test loss: 0.09641429626693328\n",
      "Test accuracy: 0.9604166547457377\n"
     ]
    }
   ],
   "source": [
    "happyModel = HappyModel(x_train.shape[1:])\n",
    "happyModel.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "happyModel.fit(x_train, y_train, epochs=10, batch_size=150)\n",
    "score = happyModel.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 1.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGSNJREFUeJztnW+sHNV5xp93Zvf6GkxqzD+5/CmE8iFR1BpkoUhUUULSiKJKgJRUpFLlSqhEVZEStZVqpVJLqn6gVUnUDxURFBSrSgM0CQJVtA1CRFG+AIYYMHFb/sgFY8uGJBY22Pfuzrz9sOPk2nuec/fM7s61Oc9Purp7z87Me2bmvDt73/ec9zF3hxAiP4q17oAQYm2Q8wuRKXJ+ITJFzi9Epsj5hcgUOb8QmSLnFyJT5PxCZIqcX4hM6U2zs5ndAOAfAZQA/tnd74ptf17Z98v6i2PtDjbL0Kbp3piVYGtkhqNZ2L4l9qvNLEpmO5WoaWaD7MR6FO0psU+7RQ5Wpx2+OVTauOLbt7GRSovncOA03hgcx0+rwUSDp7Xzm1kJ4J8A/DaAfQCeNbPH3P0nbJ/L+ot46rKrx9qHHr61MQdgl7wowhfRUQXbB4MBtVFa+Fj9oh+2QZzGKzZ0OUURvjXsmjDbFbm2AGBl+Dyq5fA16XvYdp9cJwCoh+HrXpP7VPfC7ccqcpyI85mF3+uR/pYetlHEriGG4X1K8gFD+lRhPbVBbQfGwqf2PT/x/tN87b8WwKvu/rq7LwN4EMBNUxxPCNEh0zj/xQDeXPH3vqbtJMzsdjPbaWY736n4U1YI0S3TOH/oe83Ydxp3v9fdt7r71vPJ10whRPdM4/z7AFy64u9LAOyfrjtCiK6YJtr/LICrzOwKAG8BuBXA77c5UEmirx6LeKdG0D38ORcLKrL36jotQFmW5SqdG4edHrNNYnHxoCnbpxfub0F2qCt+L9xIf1n8vg7b7pHtl0kgEACMBBV7BblPRtwhMtacjKuaBHlpBokEAmMUofNIOExr53f3oZndAeC/MEr1PeDuL7c9nhCiW6bK87v74wAen1FfhBAdohl+QmSKnF+ITJHzC5EpU/3P34aUOetFZNZ4xd5iU2zZfHUSrQUAK0iUfoYVj51E0Fkkns5Wp/P0+fkdXw5HysnMVCyTQ5V9fj2qIvzeoA5P+KrZ3H5im00NBwBD+P6xsdAjRmKB+MJJZoRMAS/LsMvVxrMWYBkeNkgmRE9+ITJFzi9Epsj5hcgUOb8QmSLnFyJT5PxCZEr3qb5Q2qSDKl6zLAiGknxm1uETGdaRNA75/C1YdRxWAYctuomkwhZ664LtlYer07w/PB5sP+7hdgCoivCx6gWSku2Hz6O3biHYbmwxDoCSpPrY7VhaIotxBjzXV5J7XrL0HFmItNiPLf4iaeqA7ZQktJ78QmSKnF+ITJHzC5Epcn4hMkXOL0SmdB7tD3/exKLh5CgkrFklinO0WaJDa+eTj1Iniz9G76X1lwSXUZMQdhUpc7W8tBxuJ4tujlt4++G6SCmts8jClw+FF770NoTbi8U0rQQAKMpwhqBH7ocfJ9F+kgUAgGIYvumDY+FrtXTsWPhAxyJZC6Yf0QucX0JaS09+ITJFzi9Epsj5hcgUOb8QmSLnFyJTppXo3gvgCEbh+qG7b41uj3CUPj3WH+1TsL1uUXqL7VGRedtMIbggyrMAj8YPSPR+OAjbZtvHouE1SR0sOymxtS68fUEi9ABg55Bo/1lkjUKfXA8i2uFFTIWYXBMmosK84ayIsAtJ8VRL4TUNFckovP8ayQIA6JFxNbTx+xRbyzF23Im35HzK3d+ZwXGEEB2ir/1CZMq0zu8Avm9mz5nZ7bPokBCiG6b92n+du+83swsBPGFm/+3uP1y5QfOhcDsAXErWjwshumeqJ7+7729+HwLwCIBrA9vc6+5b3X3r+SUPDAkhuqX1k9/MzgZQuPuR5vVnAfxNbB8Hn3ufChN3SBW1iOkepMpe18Q6m3cPAMMqHBVeHoajtqwqEJPurmJZDhL0rlhknVTfKRb5RSwWSGWehfBzZ/36cKdKoiTiCF8/gGdZ2H0dEnUOj6l2kPdYFaHCF4Pt/SPcxPtH3wu3Lx0da2P3LsQ0X/svAvBI4wg9AP/q7v85xfGEEB3S2vnd/XUAvznDvgghOkSpPiEyRc4vRKbI+YXIFDm/EJmyBmW8xmEpMjDNeYDm9JLTcBETzHxRhN+ohmShzHK4pBMADEiqj2mvs0ROTfoUy2VWCC8mqYpwOrFYH56kVW7gk7eMLIopFskiKFKuqyB120iGE0CkRBs5VkHSiVWsNBYZJL1e2LVKsqho08fOpSbeenNfsP3wwfEUYM3q2wXQk1+ITJHzC5Epcn4hMkXOL0SmyPmFyJTOo/1ugfAsFaKIhHLZQp3EqH7BSjrxbmHISm8NSTuJ6AMRkRGWtSDXhGZMIioOQyNlrnpkn8XwtaqIrDYADEkprQUS1e+vD7fXpNhbjwhzAEBdk1Ja5P5VFbkXTCkFACoyRgdhG+W6sMu9dzYfIx/69QuC7W/74fHGN+hhxtCTX4hMkfMLkSlyfiEyRc4vRKbI+YXIlE6j/Y5w1J3FUmNCG0ycgEXPmdBGLKPAMgSDQVjUYkAivMMhj+SyKL2RMlB0jQKJ6rO1DgBQleF+1SWZd0/uR2+B12Yszw7P+++RzEGxPjwk+ySqz+SrY++VLANChkJsjDBxjppkfkqy1mK4wEu9LZBrsvFXx9cDlAvhdQAh9OQXIlPk/EJkipxfiEyR8wuRKXJ+ITJl1Wi/mT0A4HcBHHL3jzVtmwA8BOByAHsB/J67/3y1Y3ld49ix8eoxLKofi1SDVK5hEXpmI1bJh6UhWDUWJodtkfnnFONrDkKQaenRazggn/01kb22KtwnI7LhAODL4feWfSnYXg3C1YX6/XBf+5G1Gb2C9JdcE2PXPKbsQoL0FVkPMGCDaolLdK/bsCHYvnHTr4y1sbEZYpIn/zcB3HBK23YAT7r7VQCebP4WQpxBrOr8jfDmz05pvgnAjub1DgA3z7hfQog50/Z//ovc/QAANL8vnF2XhBBdMPeAn5ndbmY7zWznT8n6aiFE97R1/oNmthkAmt+H2IYrJbrPK06LSuFCCLR3/scAbGtebwPw6Gy6I4ToiklSfd8G8EkA55vZPgB/DeAuAA+b2W0YFQ76/CTGrCiwuDiuT04X8DAhCvAUHV0kxBb2xFJ9hFC6MkZM3p2eI9mHZp2IkTpSgqogqS2rSQrwePga+nvhhU4A0OuH05w1SbeVvXB/+wvhPhlZ4AUABU31hbd3ciyPLB4akLTo0jAs1MIWhRWRdGlJOtzvBxZUJYznVZ3f3b9A3vr05GaEEKcbmuEnRKbI+YXIFDm/EJki5xciUzpPvIcWVRSJstoAUCSW8XJaoykSivfwZ+NCGb5sQxL5ZWIQAF8MxEQ7QLann+KxxVFEe5plFAbHw5HqpcN88tZSHY5612eFt/dFEu1fDts2suAHAPqkNBYr78XuRSzrxK7VMhFqqZz0KaID/s7P3w22W2B8DkkpuRB68guRKXJ+ITJFzi9Epsj5hcgUOb8QmdJxtN/JHHtSNioSZWVRbLZHSeZ50whvBLPwZTMi/Wwx0YeayEWzftGSZ9REhHC/CpLlqElEujrGI8x1SURUyC5kSjyOkXUFPSLpDQA9MroLct5OIvFFEXlGJlb+CkrUA4CHxU0AYLBMpN8Dpb+qYUTW/hT05BciU+T8QmSKnF+ITJHzC5Epcn4hMqXzuf2hwKmT0Gh6HJ7jFYvwplspSS1CXmSHf8YWZK+CdIvFcukagcj5WY9UxyHG2XnYkJ9fdTR8rCUSvQfJDtQkqn6sIOkBAAsL4fvE2nt9Uvknsn4AfdJf5llk7Azf5+fRY/Lr1Xi/olWjTu3K5JsKIT5IyPmFyBQ5vxCZIucXIlPk/EJkSluJ7jsB/BGAt5vNvuLuj8+6czF5aRbUZFFyWhmnBaxfbA64kYgwkC73zYoCDZkuQWxdAUiEmUmTk6pHRUTCuh6Q+vxDUoueXFuWUIjpLhQ98iYZJFVJqg71+TUckqUFFZmqX/TDLrdhiT+Ha7L+4/h7741vO+O5/d/EuEQ3AHzd3bc0PzN3fCHEfGkr0S2EOMOZ5n/+O8zsRTN7wMzOnVmPhBCd0Nb57wFwJYAtAA4AuJtteJJEN6loKoTonlbO7+4H3b3ykbLhfQCujWz7S4luUvJaCNE9rZzfzDav+PMWALtn0x0hRFe0lej+pJltwSgptBfAFycxZrBgmoyKc0QWpbB3nJX+ImmqitWTAk/DGUm90KxTVAecnAnZpc8ORdKMbNEUACwjnI+ii4FYCbGI8AlLNa4j94ndvyoixc1YQDgP1yP3w4bkPI5Fzo/cPy4eE6YCH4dOFlRt9A1jbQuBxT6MthLd909sQQhxWqIZfkJkipxfiEyR8wuRKXJ+ITLlA5d4Ty1n1U60I3GREFttBFAZ8JnZjtAjUtUsql/yfAaFRftZVL9OjPYPh3ziGFtoxUqnGc8hURup2Rp2//otnsOhsZsyPvTkFyJT5PxCZIqcX4hMkfMLkSlyfiEy5bSI9lOhgYhEN4vSs2hnaumt2D7JfYrtQ+Z0G9N+niUtMh0hWPQcAIxkFIjaNxcrIe0x2yw7wdpTxxQwWq8S7BeT6CZvFJH1EbxfAdEORfuFEKsh5xciU+T8QmSKnF+ITJHzC5Epp0W0vwtSswDR99Kmc7daPwAPZwF8hlkAI5FnVpmnYNcwYiNVXIUVPaJ9ik67ZxWJErePRvvZscj2pL0XqbhErQSOJYluIcSqyPmFyBQ5vxCZIucXIlPk/EJkyqrOb2aXmtlTZrbHzF42sy817ZvM7Akze6X5Lb0+Ic4gJkn1DQH8mbs/b2bnAHjOzJ4A8IcAnnT3u8xsO4DtAP4idiAHE5Fg5aRi6Q+yIIakhKKHIlAxihZpQ2qDpWa4AkjS8akgCoAyMdPbpoBYaios1UirNCqBLfhhi3cAnpqki3FoinNGX8ITrt8kEt0H3P355vURAHsAXAzgJgA7ms12ALg5tZ9CiLUj6ePGzC4HcDWApwFc5O4HgNEHBIALZ905IcT8mNj5zWwDgO8C+LK7v5uw3wqJ7kGbPgoh5sBEzm9mfYwc/1vu/r2m+eAJtd7m96HQvidLdIeFE4UQ3TNJtN8wEubc4+5fW/HWYwC2Na+3AXh09t0TQsyLScK91wH4AwAvmdmupu0rAO4C8LCZ3QbgDQCfX+1AhnBElZV0ii2o4GIXRCSijWjHjPQx4mWgZkNqdDm2D1vgkrpIB+DZBhrsJ8kMOkS4adqv2cmecBt87VDa9UglJfkxiUT3j8Cv16cnNyWEOJ3QDD8hMkXOL0SmyPmFyBQ5vxCZclqU8aLR8FiUnESF2Rz+WUpbpxLNKNDlA2nCEm3g1z1t+xYFqNJ3mN1pn3GkjN2UYa4nvxCZIucXIlPk/EJkipxfiEyR8wuRKZ1H+0PR6i4CubOMkqeTVn1nRFicIzVrEdu+SpQU5+sjuH1PnNs/JO9UNZv0n15lp4s5/8mjrcX4jMnLT7T/VHsLIc5Y5PxCZIqcX4hMkfMLkSlyfiEypftof0gWuk0knshLF6T+OYs61yyKHIHtU5CyOe0q+bCKRGkx6djmNekXfSIkymoDvOY9XYNBjsMi21UV1m9oA88O8PGZWrefnXc/MhKobkBIV0IS3UKI1ZDzC5Epcn4hMkXOL0SmyPmFyJRpJLrvNLO3zGxX83Pj/LsrhJgV00h0A8DX3f0fJjXmSEutxRbj1ESiO5hKbAlN49TDYLu1+CJFxSuYGETiwp7YNaSLbqjiRFIzgPSFSDUxzu5FLM1IT4OlGVukMum501Q0SX0O01PO05amm0S04wCAE2q8R8zshES3EOIMZhqJbgC4w8xeNLMHzOzcGfdNCDFHppHovgfAlQC2YPTN4G6ynyS6hTgNaS3R7e4H3b1y9xrAfQCuDe0riW4hTk9aS3Sb2eYVm90CYPfsuyeEmBfTSHR/wcy2YBTw3Avgi6sdyAzo9cZNsgivk4j+6M3w51bqQos2lGVaia0iLiQdbKWS29GepUGFQRKj4TEZcGajYoug2Bm2uH+pcthtrnliYoQvHir5c5ieeejaJgyQaSS6H5/cjBDidEMz/ITIFDm/EJki5xciU+T8QmRKp2W83B2DajnYHtw+cqyKvMvKPbEIdrwqFimllShVXceMeNqc7tSsBcukAEBN5p9z0Q7SHiontQo1eewwcY6KXKcuxFhiFtIzCuH2YeQ86Bz+KQVw9OQXIlPk/EJkipxfiEyR8wuRKXJ+ITKl02i/mQXnxbeJ9juL/tLAOosW8/UDNREAMRLdZnF7Jgk9sr920uFU8IL0iZ5Hi2h/lRjtH5L7PRyGqyoBgJfh86tSRDDQbm5/zURi2MFaVOUJZQHqhHuhJ78QmSLnFyJT5PxCZIqcX4hMkfMLkSlyfiEypfuFPYPxCr4svRNj6OEUD0v1MbGQWKqILRJiCy2MlBaLpfoY1EZie9RGES5HRsuOsbRkC9thy4CTa86uYags3C/eK8Pv9UkKt4tUHxOVYWMtRuieFwmiNXryC5Epcn4hMkXOL0SmyPmFyJRJRDsWzewZM3uhkej+atN+hZk9bWavmNlDZrYw/+4KIWbFJNH+JQDXu/vRRrbrR2b2HwD+FCOJ7gfN7BsAbsNIv4/i7qgCen00MhqJIlOBDCJ+YD0SX46IJfTYwp7EaH8sEs+i2OlR/fQvcWyxDO0TMxFbnJQoDMJ1wEl5L7Y4CUCPiKuwbIYR220yKbR82gwl5KnAyYSsOmJ8xNHmz37z4wCuB/Cdpn0HgJun6okQolMmFeosG6muQwCeAPAagMPuv0i27wNw8Xy6KISYBxM5f6PGuwXAJRip8X4ktFlo35MluvmEGiFEtyT9o+juhwH8AMDHAWw0sxMxg0sA7Cf7rJDo7nRCoRAiwiTR/gvMbGPzej2AzwDYA+ApAJ9rNtsG4NF5dVIIMXsmeRRvBrDDzEqMPiwedvd/N7OfAHjQzP4WwI8B3L/agaww9NeNZwRpGa9IlJVlCKjtFtLdLJpK5/zPMNrPSYvqs4g+EMkosB2YhHXk/FJPL7WsWRmJeHOxiyQTMy21xo4VGwcp9ykl/j+JRPeLAK4OtL+O0f//QogzEM3wEyJT5PxCZIqcX4hMkfMLkSndJt7dgGp8vrUR4YxeJHZZMRGOMm2+czQSTyazl0Rfmol5eOQ8WGUXJu7gpIIRixb3Y7bJBHt2TegaDGoBcEuT1mYDsiCVmDxivajD44rKuLOLSJU2OAVb00AzW5FqVmyMtlhzsBI9+YXIFDm/EJki5xciU+T8QmSKnF+ITJHzC5Epp8UaW75wIZLKWDtZ+0h6cP6dSl+MM7eunLHQdBtbuNSiXNYsFwOl2Eixqie/EJki5xciU+T8QmSKnF+ITJHzC5EpnUf7g9HqGUpY88UO6UZSy0DxLEB6mSt2rFkGkWl0e8oFI/Ogi+h5G9up14pnFDh0VAVsp/RGT34hMkXOL0SmyPmFyBQ5vxCZIucXIlOsyyiqmb0N4P+aP88H8E5nxk9GtmX7g2r719z9gkk27NT5TzJsttPdt8q2bMv22qCv/UJkipxfiExZS+e/V7ZlW7bXjjX7n18Isbboa78QmbImzm9mN5jZ/5jZq2a2vWPbe83sJTPbZWY752zrATM7ZGa7V7RtMrMnzOyV5ve5Hdq+08zeas59l5ndOCfbl5rZU2a2x8xeNrMvNe1zP/eI7bmfu5ktmtkzZvZCY/urTfsVZvZ0c94PmdnCrG23wt07/QFQAngNwIcBLAB4AcBHO7S/F8D5Hdn6BIBrAOxe0fb3ALY3r7cD+LsObd8J4M87OO/NAK5pXp8D4H8BfLSLc4/Ynvu5Y7SobkPzug/gaQAfB/AwgFub9m8A+OMuxt9qP2vx5L8WwKvu/rq7LwN4EMBNa9CPuePuPwTws1OabwKwo3m9A8DNHdruBHc/4O7PN6+PANgD4GJ0cO4R23PHRxxt/uw3Pw7gegDfadrnds9TWQvnvxjAmyv+3oeObk6DA/i+mT1nZrd3aPcEF7n7AWA0UAFc2LH9O8zsxebfgrn8y7ESM7scwNUYPQU7PfdTbAMdnLuZlWa2C8AhAE9g9C33sP9SYbXr8U5ZC+cP1RvoMuVwnbtfA+B3APyJmX2iQ9trzT0ArgSwBcABAHfP05iZbQDwXQBfdvd352lrAtudnLu7V+6+BcAlGH3L/Uhos3nYTmUtnH8fgEtX/H0JgP1dGXf3/c3vQwAewegGdclBM9sMAM3vQ10ZdveDzeCsAdyHOZ67mfUxcr5vufv3muZOzj1ku8tzb+wdBvADjP7n32hmJ6pmdTreY6yF8z8L4KomAroA4FYAj3Vh2MzONrNzTrwG8FkAu+N7zZzHAGxrXm8D8GhXhk84XsMtmNO526i+1P0A9rj711a8NfdzZ7a7OHczu8DMNjav1wP4DEYxh6cAfK7ZrNN7HmUtoowAbsQoCvsagL/s0O6HMcouvADg5XnbBvBtjL5iDjD6xnMbgPMAPAngleb3pg5t/wuAlwC8iJEjbp6T7d/C6KvtiwB2NT83dnHuEdtzP3cAvwHgx42N3QD+asW4ewbAqwD+DcC6eY67SX80w0+ITNEMPyEyRc4vRKbI+YXIFDm/EJki5xciU+T8QmSKnF+ITJHzC5Ep/w9kLGyRqg+v0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "img_path = 'C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise\\\\Data\\\\test\\\\pr\\\\217.JPG'\n",
    "### END CODE HERE ###\n",
    "img = image.load_img(img_path, target_size=(35, 35))\n",
    "imshow(img)\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "print(happyModel.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.50588235 0.61960784 0.84313725]\n",
      "  [0.50980392 0.64705882 0.86666667]\n",
      "  [0.50980392 0.65882353 0.88627451]\n",
      "  ...\n",
      "  [0.3372549  0.36078431 0.38823529]\n",
      "  [0.34117647 0.36078431 0.39607843]\n",
      "  [0.31372549 0.3372549  0.38039216]]\n",
      "\n",
      " [[0.26666667 0.32156863 0.41176471]\n",
      "  [0.28235294 0.3372549  0.42352941]\n",
      "  [0.2745098  0.33333333 0.40784314]\n",
      "  ...\n",
      "  [0.29411765 0.27843137 0.25882353]\n",
      "  [0.29803922 0.27843137 0.26666667]\n",
      "  [0.2745098  0.25882353 0.25490196]]\n",
      "\n",
      " [[0.21176471 0.2        0.16862745]\n",
      "  [0.25098039 0.22745098 0.17647059]\n",
      "  [0.26666667 0.23921569 0.16470588]\n",
      "  ...\n",
      "  [0.35294118 0.29803922 0.22745098]\n",
      "  [0.35686275 0.29803922 0.23529412]\n",
      "  [0.32941176 0.27843137 0.22352941]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.27058824 0.23137255 0.20392157]\n",
      "  [0.29019608 0.25882353 0.20784314]\n",
      "  [0.30980392 0.28235294 0.20392157]\n",
      "  ...\n",
      "  [0.35294118 0.32156863 0.23137255]\n",
      "  [0.35686275 0.31764706 0.25098039]\n",
      "  [0.33333333 0.29019608 0.25882353]]\n",
      "\n",
      " [[0.25490196 0.21568627 0.18823529]\n",
      "  [0.2745098  0.24313725 0.19215686]\n",
      "  [0.29019608 0.2627451  0.18431373]\n",
      "  ...\n",
      "  [0.32941176 0.29803922 0.20784314]\n",
      "  [0.32941176 0.29019608 0.22352941]\n",
      "  [0.30196078 0.25882353 0.22745098]]\n",
      "\n",
      " [[0.23137255 0.19215686 0.16470588]\n",
      "  [0.25490196 0.22352941 0.17254902]\n",
      "  [0.27843137 0.25098039 0.17254902]\n",
      "  ...\n",
      "  [0.37254902 0.34117647 0.25098039]\n",
      "  [0.36862745 0.32941176 0.2627451 ]\n",
      "  [0.34117647 0.29803922 0.26666667]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 28, 28, 1)\n",
      "(1000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train[0:3000,:,:]\n",
    "y_train = y_train[0:3000]\n",
    "x_test = x_test[0:1000,:,:]\n",
    "y_test = y_test[0:1000]\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HappyModel1(input_shape):\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = ZeroPadding2D((3, 3),input_shape=(28,28))(X_input)\n",
    "\n",
    "    X = Conv2D(32, (3, 3), strides = (1, 1), name = 'conv0')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(10, activation='softmax', name='fc')(X)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X, name='HappyModel1')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected fc to have shape (10,) but got array with shape (5,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-9dcebf5952c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mhappyModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHappyModel1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mhappyModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhappyModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    953\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    956\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    790\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    134\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    137\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected fc to have shape (10,) but got array with shape (5,)"
     ]
    }
   ],
   "source": [
    "happyModel = HappyModel1(x_train.shape[1:])\n",
    "happyModel.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "happyModel.fit(x_train, y_train, epochs=1, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (3000, 28, 28, 1)\n",
      "3000 train samples\n",
      "1000 test samples\n",
      "Train on 3000 samples, validate on 1000 samples\n",
      "Epoch 1/12\n",
      "3000/3000 [==============================] - 3s 1ms/step - loss: 1.6299 - acc: 0.6593 - val_loss: 1.0143 - val_acc: 0.7620\n",
      "Epoch 2/12\n",
      "3000/3000 [==============================] - 2s 826us/step - loss: 0.6340 - acc: 0.8487 - val_loss: 0.5557 - val_acc: 0.8310\n",
      "Epoch 3/12\n",
      "3000/3000 [==============================] - 3s 838us/step - loss: 0.4000 - acc: 0.8903 - val_loss: 0.4414 - val_acc: 0.8710\n",
      "Epoch 4/12\n",
      "3000/3000 [==============================] - 3s 842us/step - loss: 0.3213 - acc: 0.9130 - val_loss: 0.3761 - val_acc: 0.8850\n",
      "Epoch 5/12\n",
      "3000/3000 [==============================] - 3s 837us/step - loss: 0.2773 - acc: 0.9257 - val_loss: 0.3402 - val_acc: 0.9010\n",
      "Epoch 6/12\n",
      "3000/3000 [==============================] - 3s 869us/step - loss: 0.2442 - acc: 0.9350 - val_loss: 0.3221 - val_acc: 0.9020\n",
      "Epoch 7/12\n",
      "3000/3000 [==============================] - 3s 881us/step - loss: 0.2238 - acc: 0.9413 - val_loss: 0.3088 - val_acc: 0.9030\n",
      "Epoch 8/12\n",
      "3000/3000 [==============================] - 3s 1ms/step - loss: 0.2041 - acc: 0.9440 - val_loss: 0.2830 - val_acc: 0.9170\n",
      "Epoch 9/12\n",
      "3000/3000 [==============================] - 2s 801us/step - loss: 0.1836 - acc: 0.9497 - val_loss: 0.2738 - val_acc: 0.9190\n",
      "Epoch 10/12\n",
      "3000/3000 [==============================] - 2s 801us/step - loss: 0.1702 - acc: 0.9527 - val_loss: 0.2704 - val_acc: 0.9190\n",
      "Epoch 11/12\n",
      "3000/3000 [==============================] - 3s 872us/step - loss: 0.1549 - acc: 0.9580 - val_loss: 0.2691 - val_acc: 0.9170\n",
      "Epoch 12/12\n",
      "3000/3000 [==============================] - 2s 816us/step - loss: 0.1382 - acc: 0.9660 - val_loss: 0.2518 - val_acc: 0.9260\n",
      "Test loss: 0.25180383706092835\n",
      "Test accuracy: 0.926\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train[0:3000,:,:]\n",
    "y_train = y_train[0:3000]\n",
    "x_test = x_test[0:1000,:,:]\n",
    "y_test = y_test[0:1000]\n",
    "\n",
    "# if K.image_data_format() == 'channels_first':\n",
    "#     x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "#     x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "#     input_shape = (1, img_rows, img_cols)\n",
    "# else:\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(756, 35, 35, 3)\n",
      "(96, 35, 35, 3)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for filename in glob.glob('C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise\\\\Data\\\\train\\\\pb\\\\*.JPG'): \n",
    "    im=cv2.imread(filename)\n",
    "    if i == 0:\n",
    "        x_train=np.expand_dims(im, axis=0)\n",
    "        #plt.imshow(im)\n",
    "        im = np.fliplr(im)\n",
    "        x_train = np.concatenate((x_train, np.expand_dims(im, axis=0)), axis=0)\n",
    "        i=i+1\n",
    "    else:\n",
    "        x_train = np.concatenate((x_train, np.expand_dims(im, axis=0)), axis=0)\n",
    "        im = np.fliplr(im)\n",
    "        x_train = np.concatenate((x_train, np.expand_dims(im, axis=0)), axis=0)\n",
    "        \n",
    "for filename in glob.glob('C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise\\\\Data\\\\train\\\\pg\\\\*.JPG'): \n",
    "    im=cv2.imread(filename)\n",
    "    x_train = np.concatenate((x_train, np.expand_dims(im, axis=0)), axis=0)\n",
    "    im = np.fliplr(im)\n",
    "    x_train = np.concatenate((x_train, np.expand_dims(im, axis=0)), axis=0)\n",
    "\n",
    "for filename in glob.glob('C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise\\\\Data\\\\train\\\\pr\\\\*.JPG'): \n",
    "    im=cv2.imread(filename)\n",
    "    x_train = np.concatenate((x_train, np.expand_dims(im, axis=0)), axis=0)\n",
    "    im = np.fliplr(im)\n",
    "    x_train = np.concatenate((x_train, np.expand_dims(im, axis=0)), axis=0)\n",
    "    \n",
    "for filename in glob.glob('C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise\\\\Data\\\\train\\\\bb\\\\*.JPG'): \n",
    "    im=cv2.imread(filename)\n",
    "    x_train = np.concatenate((x_train, np.expand_dims(im, axis=0)), axis=0)\n",
    "    im = np.fliplr(im)\n",
    "    x_train = np.concatenate((x_train, np.expand_dims(im, axis=0)), axis=0)\n",
    "    \n",
    "for filename in glob.glob('C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise\\\\Data\\\\train\\\\bg\\\\*.JPG'): \n",
    "    im=cv2.imread(filename)\n",
    "    x_train = np.concatenate((x_train, np.expand_dims(im, axis=0)), axis=0)\n",
    "    im = np.fliplr(im)\n",
    "    x_train = np.concatenate((x_train, np.expand_dims(im, axis=0)), axis=0)\n",
    "\n",
    "for filename in glob.glob('C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise\\\\Data\\\\train\\\\br\\\\*.JPG'): \n",
    "    im=cv2.imread(filename)\n",
    "    x_train = np.concatenate((x_train, np.expand_dims(im, axis=0)), axis=0)\n",
    "    im = np.fliplr(im)\n",
    "    x_train = np.concatenate((x_train, np.expand_dims(im, axis=0)), axis=0)\n",
    "    \n",
    "i = 0\n",
    "for filename in glob.glob('C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise\\\\Data\\\\test\\\\pb\\\\*.JPG'): \n",
    "    im=cv2.imread(filename)\n",
    "    if i == 0:\n",
    "        x_test=np.expand_dims(im, axis=0)\n",
    "        i=i+1\n",
    "    else:\n",
    "        x_test = np.concatenate((x_test, np.expand_dims(im, axis=0)), axis=0)\n",
    "        \n",
    "for filename in glob.glob('C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise\\\\Data\\\\test\\\\pg\\\\*.JPG'): \n",
    "    im=cv2.imread(filename)\n",
    "    x_test = np.concatenate((x_test, np.expand_dims(im, axis=0)), axis=0)\n",
    "\n",
    "for filename in glob.glob('C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise\\\\Data\\\\test\\\\pr\\\\*.JPG'): \n",
    "    im=cv2.imread(filename)\n",
    "    x_test = np.concatenate((x_test, np.expand_dims(im, axis=0)), axis=0)\n",
    "    \n",
    "for filename in glob.glob('C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise\\\\Data\\\\test\\\\bb\\\\*.JPG'): \n",
    "    im=cv2.imread(filename)\n",
    "    x_test = np.concatenate((x_test, np.expand_dims(im, axis=0)), axis=0)\n",
    "\n",
    "for filename in glob.glob('C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise\\\\Data\\\\test\\\\bg\\\\*.JPG'): \n",
    "    im=cv2.imread(filename)\n",
    "    x_test = np.concatenate((x_test, np.expand_dims(im, axis=0)), axis=0)\n",
    "\n",
    "for filename in glob.glob('C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise\\\\Data\\\\test\\\\br\\\\*.JPG'): \n",
    "    im=cv2.imread(filename)\n",
    "    x_test = np.concatenate((x_test, np.expand_dims(im, axis=0)), axis=0)\n",
    "        \n",
    "\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(756, 5)\n",
      "[1 0 0 1 0]\n",
      "(96, 5)\n",
      "[1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# y_train = np.zeros(186*2, dtype=int)\n",
    "# y_train = np.concatenate((y_train, np.ones(192*2, dtype=int)), axis=None)\n",
    "# y_train = y_train.reshape((756, 1))\n",
    "# print(y_train.shape)\n",
    "\n",
    "# y_test = np.zeros(48, dtype=int)\n",
    "# y_test = np.concatenate((y_test, np.ones(48, dtype=int)), axis=None)\n",
    "# y_test = y_test.reshape((96, 1))\n",
    "# print(y_test.shape)\n",
    "\n",
    "y_train1 = np.tile([1,0,1,0,0],(62*2,1))\n",
    "y_train2 = np.tile([1,0,0,1,0],(62*2,1))\n",
    "y_train3 = np.tile([1,0,0,0,1],(62*2,1))\n",
    "y_train4 = np.tile([0,1,1,0,0],(64*2,1))\n",
    "y_train5 = np.tile([0,1,0,1,0],(64*2,1))\n",
    "y_train6 = np.tile([0,1,0,0,1],(64*2,1))\n",
    "\n",
    "y_train = np.concatenate((y_train1,y_train2,y_train3,y_train4,y_train5,y_train6))\n",
    "print(y_train.shape)\n",
    "print(y_train[130])\n",
    "\n",
    "y_test1 = np.tile([1,0,1,0,0],(16,1))\n",
    "y_test2 = np.tile([1,0,0,1,0],(16,1))\n",
    "y_test3 = np.tile([1,0,0,0,1],(16,1))\n",
    "y_test4 = np.tile([0,1,1,0,0],(16,1))\n",
    "y_test5 = np.tile([0,1,0,1,0],(16,1))\n",
    "y_test6 = np.tile([0,1,0,0,1],(16,1))\n",
    "\n",
    "y_test = np.concatenate((y_test1,y_test2,y_test3,y_test4,y_test5,y_test6))\n",
    "print(y_test.shape)\n",
    "print(y_test[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "(756,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "(756,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "(96,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "(96,)\n"
     ]
    }
   ],
   "source": [
    "y_train_p = np.tile([0],(62*6))\n",
    "y_train_b = np.tile([1],(64*6))\n",
    "y_train1 = np.concatenate((y_train_p,y_train_b))\n",
    "print(y_train1)\n",
    "print(y_train1.shape)\n",
    "\n",
    "y_train_bl = np.tile([0],(62*2))\n",
    "y_train_g = np.tile([1],(62*2))\n",
    "y_train_r = np.tile([2],(62*2))\n",
    "y_train_bl2 = np.tile([0],(64*2))\n",
    "y_train_g2 = np.tile([1],(64*2))\n",
    "y_train_r2 = np.tile([2],(64*2))\n",
    "y_train2 = np.concatenate((y_train_bl,y_train_g,y_train_r,y_train_bl2,y_train_g2,y_train_r2))\n",
    "print(y_train2)\n",
    "print(y_train2.shape)\n",
    "\n",
    "y_test_p = np.tile([0],(16*3))\n",
    "y_test_b = np.tile([1],(16*3))\n",
    "y_test1 = np.concatenate((y_test_p,y_test_b))\n",
    "print(y_test1)\n",
    "print(y_test1.shape)\n",
    "\n",
    "y_test_bl = np.tile([0],(16))\n",
    "y_test_g = np.tile([1],(16))\n",
    "y_test_r = np.tile([2],(16))\n",
    "y_test2 = np.concatenate((y_test_bl,y_test_g,y_test_r,y_test_bl,y_test_g,y_test_r))\n",
    "print(y_test2)\n",
    "print(y_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_y1_train = to_categorical(y_train1, 2)\n",
    "cat_y2_train = to_categorical(y_train2, 3)\n",
    "cat_y1_test = to_categorical(y_test1, 2)\n",
    "cat_y2_test = to_categorical(y_test2, 3)\n",
    "#y_train = np.concatenate((cat_y1_train, cat_y2_train), axis=1)\n",
    "#y_test = np.concatenate((cat_y1_test, cat_y2_test), axis=1)\n",
    "#y_train.shape\n",
    "#y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HappyModel(input_shape):\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    X = Conv2D(32, (3, 3), strides = (1, 1), name = 'conv0')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(64, (3, 3), strides = (1, 1), name = 'conv1')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "    X = Dropout(0.25)(X)\n",
    "    X = Flatten()(X)\n",
    "    y1 = Dense(2, activation='softmax')(X)\n",
    "    y2 = Dense(3, activation='softmax')(X)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = [y1, y2], name='HappyModel')\n",
    "    #model = Model(inputs = X_input, outputs = y2, name='HappyModel')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "756/756 [==============================] - 30s 39ms/step - loss: 3.2973 - dense_3_loss: 2.2096 - dense_4_loss: 1.0877 - dense_3_acc: 0.5622 - dense_4_acc: 0.7447\n",
      "Epoch 2/8\n",
      "756/756 [==============================] - 28s 37ms/step - loss: 0.9621 - dense_3_loss: 0.8990 - dense_4_loss: 0.0631 - dense_3_acc: 0.6958 - dense_4_acc: 0.9868\n",
      "Epoch 3/8\n",
      "756/756 [==============================] - 28s 36ms/step - loss: 0.4143 - dense_3_loss: 0.4142 - dense_4_loss: 1.0383e-04 - dense_3_acc: 0.8228 - dense_4_acc: 1.0000\n",
      "Epoch 4/8\n",
      "756/756 [==============================] - 28s 36ms/step - loss: 0.2614 - dense_3_loss: 0.2614 - dense_4_loss: 1.1984e-07 - dense_3_acc: 0.8862 - dense_4_acc: 1.0000\n",
      "Epoch 5/8\n",
      "756/756 [==============================] - 28s 36ms/step - loss: 0.1115 - dense_3_loss: 0.1115 - dense_4_loss: 1.5177e-07 - dense_3_acc: 0.9577 - dense_4_acc: 1.0000\n",
      "Epoch 6/8\n",
      "756/756 [==============================] - 28s 37ms/step - loss: 0.0690 - dense_3_loss: 0.0690 - dense_4_loss: 1.1937e-07 - dense_3_acc: 0.9735 - dense_4_acc: 1.0000\n",
      "Epoch 7/8\n",
      "756/756 [==============================] - 28s 37ms/step - loss: 0.0617 - dense_3_loss: 0.0617 - dense_4_loss: 1.1976e-07 - dense_3_acc: 0.9735 - dense_4_acc: 1.0000\n",
      "Epoch 8/8\n",
      "756/756 [==============================] - 28s 37ms/step - loss: 0.0478 - dense_3_loss: 0.0478 - dense_4_loss: 1.1929e-07 - dense_3_acc: 0.9828 - dense_4_acc: 1.0000\n",
      "Test loss: 0.1456528907486548\n",
      "Test accuracy: 0.14521982326793173\n",
      "Test accuracy: 0.00043307194331039983\n",
      "Test accuracy: 0.9479166666666666\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "happyModel = HappyModel(x_train.shape[1:])\n",
    "happyModel.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "happyModel.fit(x_train, [cat_y1_train, cat_y2_train], epochs=8, batch_size=150)\n",
    "#happyModel.fit(x_train, cat_y2_train, epochs=15, batch_size=150)\n",
    "score = happyModel.evaluate(x_test, [cat_y1_test, cat_y2_test], verbose=0)\n",
    "#score = happyModel.evaluate(x_test, cat_y2_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test accuracy:', score[2])\n",
    "print('Test accuracy:', score[3])\n",
    "print('Test accuracy:', score[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0.]\n",
      "[array([[1., 0.]], dtype=float32), array([[1., 0., 0.]], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "img_path = 'C:\\\\Users\\\\Marakhi\\\\Desktop\\\\Deep learning ajay bhammar\\\\Deep learning exercise\\\\Data\\\\test\\\\pb\\\\218.JPG'\n",
    "# ### END CODE HERE ###\n",
    "img = image.load_img(img_path, target_size=(35, 35))\n",
    "#img = x_test[0]\n",
    "print(cat_y2_test[0])\n",
    "imshow(img)\n",
    "#imshow(x_test[0])\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "#x = preprocess_input(x)\n",
    "\n",
    "print(happyModel.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'dense_5_loss', 'dense_6_loss', 'dense_5_acc', 'dense_6_acc']\n"
     ]
    }
   ],
   "source": [
    "print(happyModel.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(cat_y2_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
